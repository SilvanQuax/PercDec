{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test object categorization under noise as an RL task\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/squax/GitHub/CMS/')\n",
    "from agent.reinforcement import *\n",
    "from brain.monitor import *\n",
    "from brain.models import ActorCriticModel\n",
    "from brain.networks import *\n",
    "from world.base import World\n",
    "from world.data import *\n",
    "from world.tasks import *\n",
    "from brain.links import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tools\n",
    "%matplotlib inline \n",
    "\n",
    "start_time=time.strftime(\"%H:%M:%S\")\n",
    "# parameters\n",
    "n_epochs = 1\n",
    "n_level = [0.5]\n",
    "coh_all=(100-np.logspace(np.log10(100),np.log10(3.125),num=6))/100#[0.5,0.75,0.85,0.92]# [1 - x for x in [0.08, 0.15, 0.25, 0.5]]\n",
    "\n",
    "rwrds = [0, 1, 0] ###test -> 0\n",
    "i_class = [0, 1]\n",
    "train_batch = 50000\n",
    "test_batch = 20000\n",
    "fix_length=3\n",
    "trial_length=50\n",
    "gamma = 0.999\n",
    "\n",
    "num_obs = np.zeros(len(coh_all))\n",
    "bin_obs = np.zeros((len(coh_all), 100))\n",
    "acc = np.zeros((len(coh_all),100))\n",
    "acc1 = np.zeros(len(coh_all))\n",
    "\n",
    "nobs_all = np.zeros((len(n_level), 40))\n",
    "mobs_all = np.zeros((len(n_level), 40))\n",
    "\n",
    "gpu=-1\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "if gpu==1:\n",
    "    chainer.cuda.get_device_from_id(1).use()\n",
    "\n",
    "for iii in xrange(len(n_level)):\n",
    "    # get training data - note that we select a subset of datapoints (n_samples is nr of samples per class)\n",
    "    train_data = MNISTData(test=False, convolutional=False, n_samples=1000, classes = [0,1],centre=False)\n",
    "\n",
    "    # define iterator\n",
    "    data_iter = DataTaskMnist(train_data, batch_size=1, n_batches=train_batch, coh_all=coh_all, rewards=rwrds, noise_method=1,\n",
    "                         fix_length=fix_length, trial_length=trial_length)\n",
    "\n",
    "    # an actor-critic model assumes that the predictor's output is number of actions plus one for the value\n",
    "    n_output = data_iter.n_output\n",
    "    n_input = data_iter.n_input\n",
    "    # define brain of agent\n",
    " \n",
    "    model = ActorCriticModel(RNN2(n_input, n_output, n_hidden=100, link=GRU_custom))  \n",
    "                                                            ###test ->100\n",
    "    # save model\n",
    "    fname = 'result/model_mnist22_fl'+str(fix_length)+'_l' + str(trial_length) + '_g' + str(gamma).replace('.', '') + '_r' + str(rwrds[0]).replace('.', '')\n",
    "    #fname = 'result/model_mnist32_fl'+str(fix_length)+'_l' + str(trial_length) + '_g' + str(gamma).replace('.', '') + '_r' + str(rwrds[0]).replace('.', '')\n",
    "\n",
    "    ###test\n",
    "\n",
    "    #_fl'+str(fix_length)\n",
    "    model.load(fname)\n",
    "\n",
    "    monitor = Oscilloscope(names=['p1', 'p2', 'p3'])\n",
    "    model.add_monitor(monitor)\n",
    "    # define agent: only entropy on state actions\n",
    "    agent = ActorCriticAgent(model, chainer.optimizers.Adam(alpha=0.0005), cutoff=train_batch, beta=1e-2, gamma=gamma, aac=True, gpu=gpu)  # Adam(alpha=0.0005)\n",
    "\n",
    "    # add gradient clipping\n",
    "    agent.optimizer.add_hook(chainer.optimizer.GradientClipping(1))\n",
    "\n",
    "    agent.add_monitor(monitor)\n",
    "    # # add oscilloscope\n",
    "    agent.add_monitor(Oscilloscope(names=['cumulative reward']))\n",
    "    agent.add_monitor(Monitor(names=['action']))\n",
    "    data_iter.add_monitor(Monitor(names=['state','step']))\n",
    "\n",
    "    monitor = Oscilloscope(names=['accuracy','resp_ratio'])\n",
    "    data_iter.add_monitor(monitor)\n",
    "    agent.add_monitor(monitor)\n",
    "\n",
    "    # define world\n",
    "    world = World(agent)\n",
    "\n",
    "    # create test data\n",
    "    val_data = MNISTData(test=True, convolutional=False, n_samples=1000, classes=[0,1], centre=False)\n",
    "    val_iter = DataTaskMnist(val_data, batch_size=1, n_batches=test_batch, coh_all=coh_all, rewards=rwrds, noise_method=1,\n",
    "                        fix_length=fix_length, trial_length=trial_length)\n",
    "\n",
    "    # add monitor to model and iterator\n",
    "    agent.add_monitor(Monitor(names=['action']))\n",
    "    val_iter.add_monitor(Monitor(names=['state','step']))\n",
    "    val_iter.add_monitor(Monitor(names=['coh']))\n",
    "\n",
    "    monitor = Oscilloscope(names=['accuracy'])\n",
    "    val_iter.add_monitor(monitor)\n",
    "    agent.add_monitor(monitor)\n",
    "\n",
    "    monitor1 = Oscilloscope(names=['p1', 'p2', 'p3','hidden-1','hidden-2'])\n",
    "    model.add_monitor(monitor1)\n",
    "\n",
    "\n",
    "    monitor = Monitor()\n",
    "    agent.add_monitor(monitor)\n",
    "    val_iter.add_monitor(monitor)\n",
    "\n",
    "    # run in test mode\n",
    "    world.test(val_iter, n_epochs=1, plot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get variables\n",
    "Y1 = monitor['action']\n",
    "T1 = monitor['state']\n",
    "C1 = monitor['coh']\n",
    "\n",
    "p1 = monitor1['p1']\n",
    "p2 = monitor1['p2']\n",
    "p3 = monitor1['p3']\n",
    "h1 = monitor1['hidden-1']\n",
    "h2 = monitor1['hidden-2']\n",
    "\n",
    "nacc = np.zeros((len(coh_all),100))\n",
    "\n",
    "A1 = np.zeros(Y1.shape)\n",
    "C = np.zeros((2, len(Y1)))\n",
    "\n",
    "temp = 0\n",
    "for ii in xrange(len(Y1)):\n",
    "    temp = temp + 1\n",
    "    A1[ii] = temp\n",
    "    if Y1[ii] != (data_iter.n_output - 1) or temp == trial_length+1:\n",
    "        C[T1[ii], ii] = temp\n",
    "        temp = 0\n",
    "\n",
    "p1m = np.zeros((2, 40, 40))\n",
    "p1m[:]=np.nan\n",
    "p2m = np.zeros((2, 40, 40))\n",
    "p3m = np.zeros((2, 40, 40))\n",
    "\n",
    "for ic in xrange(2):\n",
    "    for ii in xrange(40):\n",
    "        idx = np.where(C[ic, :] == ii + 1)\n",
    "        idx1 = []\n",
    "        for i2 in xrange(ii + 1):\n",
    "            idx1 = [x - ii + i2 for x in list(idx)]\n",
    "            p1m[ic, ii, i2] = np.mean(p1[idx1])\n",
    "            p2m[ic, ii, i2] = np.mean(p2[idx1])\n",
    "            p3m[ic, ii, i2] = np.mean(p3[idx1])\n",
    "\n",
    "# only focus on those trials at which a decision is being made\n",
    "idx = np.where(Y1 != data_iter.n_output - 1)[0]\n",
    "Y = Y1[idx]\n",
    "T = T1[idx]\n",
    "A = A1[idx]\n",
    "C2 = C1[idx]\n",
    "\n",
    "idx = np.where(A > fix_length)[0]\n",
    "Y3 = Y[idx]\n",
    "T3 = T[idx]\n",
    "A3 = A[idx]\n",
    "C3 = C2[idx]\n",
    "\n",
    "B = np.equal(Y, T)\n",
    "\n",
    "stepsize=2\n",
    "bins=50/stepsize\n",
    "bin_obs = np.zeros((len(coh_all), bins))\n",
    "bin_obs_co = np.zeros((len(coh_all), bins))\n",
    "bin_obs_uc = np.zeros((len(coh_all), bins))\n",
    "print(max(A))\n",
    "coh=np.unique(C2)\n",
    "for ii in xrange(len(coh)):\n",
    "    idx1 = list(np.where(C2 == coh[ii]))\n",
    "    num_obs[ii] = np.mean(A[idx1])\n",
    "    bin_obs[ii] = np.histogram(A[idx1].astype('int32'), bins=bins,range=(1,trial_length+1))[0]\n",
    "    \n",
    "    idx11 = list(np.where((C2 == coh[ii])&(B==1)))\n",
    "    idx12 = list(np.where((C2 == coh[ii])&(B==0)))\n",
    "\n",
    "    bin_obs_co[ii] = np.histogram(A[idx11].astype('int32'), bins=bins,range=(1,trial_length+1))[0]\n",
    "    bin_obs_uc[ii] = np.histogram(A[idx12].astype('int32'), bins=bins,range=(1,trial_length+1))[0]\n",
    "\n",
    "### accuracy\n",
    "\n",
    "for ii in xrange(len(coh)):\n",
    "    idx1 = list(np.where(C2 == coh[ii]))\n",
    "    acc1[ii] = np.sum(B[idx1]) / float(len(idx1[0]))\n",
    "    for iii in xrange(50):\n",
    "        idx2 = list(np.where((A == iii + 1) & (C2 == coh[ii])))\n",
    "        if len(idx2[0])>1:\n",
    "            acc[ii,iii] = np.sum(B[idx2])\n",
    "            nacc[ii,iii] = float(len(idx2[0]))\n",
    "\n",
    "nobs_acc=np.zeros((len(coh),2))\n",
    "acc_nobs=np.zeros((len(coh),2))   \n",
    "\n",
    "nobs_acc_err=np.zeros((len(coh),2))\n",
    "P=np.zeros((len(coh)))\n",
    "P2=np.zeros((len(coh)))\n",
    "\n",
    "Corr=np.zeros((len(coh)))\n",
    "for ii in xrange(len(coh)):\n",
    "    idx1 = list(np.where((C2 == coh[ii]) & (B==1)))\n",
    "    idx2 = list(np.where((C2== coh[ii]) & (B!=1)))\n",
    "    idx3 = list(np.where(C2== coh[ii]))\n",
    "    idx4 = np.argsort(A[idx3])\n",
    "    B2= B[idx3]\n",
    "    acc_nobs[ii,1]=np.mean(B2[idx4[:(len(idx3[0])/2)]])\n",
    "    acc_nobs[ii,0]=np.mean(B2[idx4[(len(idx3[0])/2):]])\n",
    "    nobs_acc[ii,1]=np.mean(A[idx1])\n",
    "    nobs_acc[ii,0]=np.mean(A[idx2])\n",
    "    nobs_acc_err[ii,1]=sst.sem(A[idx1])\n",
    "    nobs_acc_err[ii,0]=sst.sem(A[idx2])\n",
    "    \n",
    "    if0=np.sum(B2[idx4[:(len(idx3[0])/2)]]==False)\n",
    "    if1=np.sum(B2[idx4[:(len(idx3[0])/2)]]==True)\n",
    "    is0=np.sum(B2[idx4[(len(idx3[0])/2):]]==False)\n",
    "    is1=np.sum(B2[idx4[(len(idx3[0])/2):]]==True)\n",
    "\n",
    "    c_table=np.array([[if0,if1],[is0,is1]])\n",
    "    Corr[ii]=sst.chi2_contingency(c_table)[1]\n",
    "    P[ii]=sst.ttest_ind_from_stats(nobs_acc[ii,0],np.std(A[idx2]),len(idx2[0]),\n",
    "                                   nobs_acc[ii,1],np.std(A[idx1]),len(idx1[0]))[1]\n",
    "    \n",
    "    P2[ii]=sst.ttest_ind(np.log(A[idx2]),np.log(A[idx1]))[1]\n",
    "\n",
    "\n",
    "\n",
    "nobs_acc_all= np.zeros(2)\n",
    "nobs_acc_err_all= np.zeros(2)\n",
    "\n",
    "nobs_acc_all[1]=np.mean(nobs_acc[:,1])\n",
    "nobs_acc_all[0]=np.mean(nobs_acc[:,0])\n",
    "nobs_acc_err_all[1]=sst.sem(nobs_acc[:,1])\n",
    "nobs_acc_err_all[0]=sst.sem(nobs_acc[:,0])\n",
    "\n",
    "#### hidden state activities\n",
    "FR = np.zeros((2,len(coh_all),100))\n",
    "for iiii in xrange(2):\n",
    "    for iii in xrange(len(coh_all)):\n",
    "        for ii in xrange(100):\n",
    "            idx = np.where((A1 == ii+1) & (C1 == coh_all[iii]) & (T1 == iiii))\n",
    "            FR[iiii,iii,ii] = np.mean(h1[idx,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib.rcParams.update({'font.size': 8})\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy as sy\n",
    "d = 100-coh_all*100\n",
    "d2= np.linspace(0,100,100)\n",
    "\n",
    "aa=[]\n",
    "for ii in xrange(len(coh_all)):\n",
    "    aa.append('{0:.1f}'.format(coh_all[ii]*100).rstrip('0').rstrip('.'))\n",
    "    \n",
    "# psychometric function\n",
    "def pf(x, alpha, beta):\n",
    "    return 1. / (1 + np.exp( -(x-alpha)/beta ))\n",
    "\n",
    "par0 = sy.array([0., 1])\n",
    "par, mcov = curve_fit(pf, d, acc1, par0)\n",
    "\n",
    "\n",
    "p=np.polyfit(np.log(100-coh_all*100),num_obs,1)\n",
    "x_fit=np.log(100-coh_all*100)\n",
    "y_fit=x_fit*p[0]+p[1]\n",
    "\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(8,2.7))\n",
    "plt.figure(figsize=(5.2,5))\n",
    "\n",
    "plt.subplot(221)\n",
    "#plt.semilogx(100-coh_all[[0,2]]*100,acc1[[0,2]],'ro')\n",
    "plt.semilogx(100-coh_all[[0,1,2,3,4,5]]*100,acc1[[0,1,2,3,4,5]],'ko')\n",
    "plt.semilogx(d2, pf(d2, par[0], par[1]),'k')\n",
    "plt.xlim(1,100)\n",
    "plt.ylim(0.5,1)\n",
    "plt.xlabel('Signal strength (100 - % noise)')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(222)\n",
    "#plt.semilogx(100-coh_all[[0,2]]*100,num_obs[[0,2]],'ro')\n",
    "plt.semilogx(100-coh_all[[0,1,2,3,4,5]]*100,num_obs[[0,1,2,3,4,5]],'ko')\n",
    "plt.semilogx(100-coh_all*100,y_fit,'k')\n",
    "plt.xlim(1,100)\n",
    "plt.xlabel('Signal strength (100 - % noise)')\n",
    "plt.ylabel('Mean number of observations')\n",
    "\n",
    "plt.subplot(223)\n",
    "for ii in xrange(6):\n",
    "    if np.isin(ii,np.arange(6)):\n",
    "        plt.plot(np.arange(1,31,stepsize),bin_obs[ii,:30/stepsize].T,'-')\n",
    "    else:\n",
    "        bbb=plt.plot(np.arange(1,31,stepsize),bin_obs[ii,:30/stepsize].T,'--')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Trial length count')\n",
    "    \n",
    "leg = plt.legend(aa,fontsize=7.5)\n",
    "leg.set_title('Noise')\n",
    "\n",
    "plt.subplot(224)\n",
    "bin_sz = 7\n",
    "lentr = 98\n",
    "acc[acc==0]=np.nan\n",
    "#plt.plot(acc.T)\n",
    "accres = acc[:,:lentr].reshape(6,-1,bin_sz)\n",
    "naccres = nacc[:,:lentr].reshape(6,-1,bin_sz)\n",
    "accall=np.nansum(accres,2)/np.nansum(naccres,2)\n",
    "accall[np.nansum(naccres,2)<50]=np.nan\n",
    "plt.plot(np.arange(1,lentr,bin_sz),accall.T)\n",
    "plt.xlim([0,30])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "leg = plt.legend(aa,fontsize=7.5,loc='lower right')\n",
    "leg.set_title('Noise')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "###\n",
    "plt.figure(figsize=(5.2,2.6))\n",
    "plt.subplot(121)\n",
    "for ii in xrange(6):\n",
    "    if np.isin(ii,np.arange(6)):\n",
    "        print(stepsize)\n",
    "        plt.plot(np.arange(1,31,stepsize),bin_obs_co[ii,:30/stepsize].T/np.nansum(bin_obs_co[ii,:30/stepsize]),'-')\n",
    "    else:\n",
    "        bbb=plt.plot(np.arange(1,31,stepsize),bin_obs[ii,:30/stepsize].T,'--')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Trial length count')\n",
    "    \n",
    "leg = plt.legend(aa,fontsize=7.5)\n",
    "leg.set_title('Noise')\n",
    "\n",
    "plt.subplot(122)\n",
    "for ii in xrange(6):\n",
    "    if np.isin(ii,np.arange(6)):\n",
    "        print(stepsize)\n",
    "        plt.plot(np.arange(1,31,stepsize),bin_obs_uc[ii,:30/stepsize].T/np.nansum(bin_obs_uc[ii,:30/stepsize]),'-')\n",
    "    else:\n",
    "        bbb=plt.plot(np.arange(1,31,stepsize),bin_obs[ii,:30/stepsize].T,'--')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Trial length count')\n",
    "    \n",
    "leg = plt.legend(aa,fontsize=7.5)\n",
    "leg.set_title('Noise')\n",
    "plt.tight_layout()\n",
    "\n",
    "###\n",
    "plt.figure(figsize=(8,2.7))\n",
    "plt.subplot(131)\n",
    "plt.plot(coh_all*100,acc1,'ko-')\n",
    "\n",
    "plt.xlim(1,100)\n",
    "plt.ylim(0.5,1)\n",
    "plt.xlabel('Noise')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(coh_all*100,num_obs,'ko-')\n",
    "plt.xlim(1,100)\n",
    "plt.xlabel('Noise')\n",
    "plt.ylabel('Number of observations')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(np.arange(1,31,stepsize),bin_obs[:,:30/stepsize].T,'-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Trial length count')\n",
    "    \n",
    "leg = plt.legend(aa,fontsize=7.5)\n",
    "leg.set_title('Noise')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "###\n",
    "\n",
    "idx1 = list(np.where((C2 == coh[2]) & (B==1)))\n",
    "idx2 = list(np.where((C2 == coh[2]) & (B!=1)))\n",
    "\n",
    "X=np.concatenate((A[idx1],A[idx2])).reshape(-1,1)\n",
    "y=np.concatenate((B[idx1],B[idx2]))\n",
    "from sklearn import linear_model\n",
    "X_test = np.linspace(1, 30, 100)\n",
    "clf = linear_model.LogisticRegression(C=1e5)\n",
    "clf.fit(X, y)\n",
    "def model(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "loss = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "# and plot the result\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.clf()\n",
    "\n",
    "idx=230\n",
    "for ii in xrange(len(coh_all)):\n",
    "    idx=idx+1\n",
    "    plt.subplot(idx)\n",
    "    plt.errorbar([0,1],nobs_acc[ii].T, yerr=nobs_acc_err[ii], color='black', capsize=4)\n",
    "    plt.xlim((-0.5,1.5))\n",
    "    plt.margins(y=0.5)\n",
    "    plt.xticks([0,1],('Incorrect','Correct'))\n",
    "    plt.title('N = '+ str(coh_all[ii]))\n",
    "    #plt.xlabel('Classification')\n",
    "\n",
    "    plt.ylabel('Trial length')\n",
    "\n",
    "plt.xlim((-0.5,1.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,2.3))\n",
    "plt.subplot(131)\n",
    "plt.plot(coh_all*100,acc1,'o-')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Noise percentage')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(coh_all*100,num_obs-3,'o-')\n",
    "plt.xlabel('Noise percentage')\n",
    "plt.ylabel('Number of observations')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(np.arange(1,41,stepsize),bin_obs[:,:40/stepsize].T,'-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Trial length count')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.subplot(121)\n",
    "plt.errorbar([0,1],nobs_acc_all.T, yerr=nobs_acc_err_all, color='black', capsize=4)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.bar(np.arange(12), acc_nobs.reshape((12)))\n",
    "plt.ylim((0.8,1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "dist= np.zeros(10)\n",
    "for ii in xrange(10):\n",
    "    kmeans = KMeans(n_clusters=ii+1, random_state=0).fit(h1.T)\n",
    "    print(ii)\n",
    "    dist[ii] = kmeans.inertia_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cls=4\n",
    "#aa=str(coh_all*100)[1:-1].split()[:]\n",
    "#aa='{0:.2f}'.format(aa)\n",
    "#aa=['N = ' + x for x in aa]\n",
    "aa=[]\n",
    "for ii in xrange(len(coh_all)):\n",
    "    aa.append('{0:.1f}'.format(coh_all[ii]*100).rstrip('0').rstrip('.'))\n",
    "\n",
    "FR = np.zeros((2,len(coh_all),50))\n",
    "FR[:] = np.nan\n",
    "FRH = np.zeros((2,len(coh_all),50))\n",
    "FRH[:] = np.nan\n",
    "FRH2 = np.zeros((cls,2,len(coh_all),50))\n",
    "FRH2[:] = np.nan\n",
    "hm=[]\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=cls, random_state=0).fit(h1.T)\n",
    "for ii in xrange(cls):\n",
    "    hm.append(np.mean(h1[:,kmeans.labels_==ii],axis=1))\n",
    "    \n",
    "for iiii in xrange(2):\n",
    "    for iii in xrange(len(coh_all)):\n",
    "        for ii in xrange(50):\n",
    "            idx = np.where((A1 == ii+1) & (C1 == coh_all[iii]) & (T1 == iiii))\n",
    "            if len(idx[0])>20:\n",
    "                FR[iiii,iii,ii] = np.mean(p2[idx])\n",
    "                FRH[iiii,iii,ii] = np.mean(p3[idx])\n",
    "                for cl in xrange(cls):\n",
    "                    FRH2[cl,iiii,iii,ii] = np.mean(hm[cl][idx])\n",
    "\n",
    "            else:\n",
    "                FR[iiii,iii,ii] = None\n",
    "                FRH[iiii,iii,ii] = None\n",
    "                FRH2[cl,iiii,iii,ii] = None\n",
    "\n",
    "idx = np.where((A1 == 1) & (C1 == coh_all[5]) & (T1 == 0))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.clf()\n",
    "plt.plot(FR[0,:,:40].T,'-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FR')\n",
    "plt.legend(coh_all)\n",
    "plt.ylim((0,1))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.clf()\n",
    "plt.plot(FRH[0,:,:40].T,'-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FR')\n",
    "plt.legend(coh_all)\n",
    "plt.show()\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "plt.figure(figsize=(8,4.9))\n",
    "\n",
    "cls_order=[0,3,2,1]\n",
    "print(cls)\n",
    "plt.clf()\n",
    "for iii in xrange(2):\n",
    "    for ii in xrange(cls):\n",
    "\n",
    "        plt.subplot(2,cls,1+ii+4*iii)\n",
    "        plt.plot(FRH2[cls_order[ii],iii,:,:40].T,'-')\n",
    "        plt.xlabel('Time')\n",
    "        if 1+ii+4*iii==1 or 1+ii+4*iii==5:\n",
    "            \n",
    "            plt.ylabel('Resp. stim '+str(iii+1))\n",
    "            \n",
    "        if iii==0:\n",
    "            plt.title('Cluster '+str(ii+1))\n",
    "        plt.yticks([], [])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylim((0,1))\n",
    "        plt.xlim((0,41))\n",
    "        if ii==2 and iii==0:\n",
    "            plt.legend(aa,fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###\n",
    "plt.figure(figsize=(8,2.7))\n",
    "\n",
    "cls_order=[0,3,2,1]\n",
    "print(cls)\n",
    "plt.clf()\n",
    "for ii in xrange(cls):\n",
    "\n",
    "    plt.subplot(1,cls,1+ii)\n",
    "    plt.plot(FRH2[cls_order[ii],0,:,:40].T,'-')\n",
    "    plt.gca().set_color_cycle(None)\n",
    "    plt.plot(FRH2[cls_order[ii],1,:,:40].T,'--')\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    if 1+ii==1:\n",
    "        plt.ylabel('Resp. stim '+str(iii+1))\n",
    "\n",
    "\n",
    "    plt.title('Cluster '+str(ii+1))\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylim((0,1))\n",
    "    plt.xlim((0,41))\n",
    "    if ii==2:\n",
    "        leg = plt.legend(aa,fontsize=8)\n",
    "        leg.set_title('Noise')\n",
    "plt.show()\n",
    "###\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "plt.figure(figsize=(8,2.7))\n",
    "plt.subplot(131)\n",
    "plt.plot(FR[1,:,:40].T,'-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('P(match)')\n",
    "plt.ylim((0,1))\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(FR[0,:,:40].T,'-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('P(non-match)')\n",
    "plt.ylim((0,1))\n",
    "leg = plt.legend(aa,fontsize=8)\n",
    "leg.set_title('Noise')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(FRH[0,:,:40].T,'-')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('P(observation)')\n",
    "plt.ylim((0,1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=150\n",
    "\n",
    "fname = 'result/model_mnist25_fl'+str(fix_length)+'_l' + str(trial_length) + '_g' + str(gamma).replace('.', '') + '_r' + str(rwrds[0]).replace('.', '')\n",
    "\n",
    "data=np.load(fname + '_log.npz')\n",
    "print(data.items())\n",
    "crwrd=data['arr_0']\n",
    "r1=np.diff(crwrd)\n",
    "r1=r1[r1!=0]\n",
    "r1_last=len(a1)-np.mod(len(a1),res)\n",
    "\n",
    "print(len(crwrd[0::res]))\n",
    "rwrd_rate=crwrd[res::res]-crwrd[0:-res:res]\n",
    "a1=data['arr_1']\n",
    "NaN_val = [a1==None][0]\n",
    "a1[a1==None]=0.5\n",
    "\n",
    "acc_trial=np.nanmean(1.0*np.reshape(a1[:r1_last],(-1,res)),axis=1)\n",
    "resp_rat = 1-np.nanmean(1.0*np.reshape(NaN_val[:r1_last],(-1,res)),axis=1)\n",
    "\n",
    "#actions\n",
    "action = data['arr_2']\n",
    "idx = np.where(action<2)\n",
    "T_len = np.diff(idx[0])\n",
    "idx2 = [T_len>2]\n",
    "idx3 = np.insert(idx2,np.where(T_len>=50)[0],False)\n",
    "idx4 = np.insert(idx3,np.where(T_len>=100)[0],False)\n",
    "\n",
    "print(len(a1))\n",
    "\n",
    "plt.figure(figsize=(8,2.6))\n",
    "plt.clf()\n",
    "plt.subplot(131)\n",
    "plt.plot(crwrd,'k')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Cumulative reward')\n",
    "\n",
    "plt.subplot(133)\n",
    "trials = np.arange(0,len(acc_trial))*r1_last/len(acc_trial)\n",
    "plt.plot(trials,acc_trial,'k')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.subplot(132)\n",
    "trials = np.arange(0,len(acc_trial))*r1_last/len(acc_trial)\n",
    "plt.plot(trials,resp_rat,'k')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('% responded in time')\n",
    "plt.ylim([0,1])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "jkl = np.arange(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed accuracy trade-off\n",
    "aa=str(coh_all)[1:-1].split()[:]\n",
    "aa=['N = ' + x for x in aa]\n",
    "\n",
    "from cycler import cycler\n",
    "acc_sa=np.empty((3,6))\n",
    "nobs_sa=np.empty((3,6))\n",
    "\n",
    "acc_sa[2]= np.asarray([0.99318569,0.99353796,0.98214286,0.9609375,0.81722054,0.705])\n",
    "nobs_sa[2]=np.asarray([4.70357751,4.60581583,5.07142857,5.5515625,6.0407855,6.18166667])\n",
    "\n",
    "acc_sa[1]=np.asarray([0.99007444,0.98726115,0.97811816,0.94209354,0.80694143,0.72463768])\n",
    "nobs_sa[1]=np.asarray([6.0942928,6.05307856,7.04595186,7.86414254,8.78958785,9.39130435])\n",
    "\n",
    "acc_sa[0]=np.asarray([0.98477157,0.99137931,0.97101449,0.93859649,0.8893617,0.74369748])\n",
    "nobs_sa[0]=np.asarray([6.24365482,7.64655172,10.69082126,16.26754386,20.88510638,23.98739496])\n",
    "\n",
    "cost=[0, -0.005, -0.01]\n",
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "print(coh_all)\n",
    "plt.figure(20,figsize=(6,5.7))\n",
    "plt.subplot(221)\n",
    "plt.xlabel('Noise')\n",
    "\n",
    "plt.semilogx(100-coh_all*100,acc_sa.T,'o-')\n",
    "\n",
    "plt.ylim(0.65,1)\n",
    "ax0 = plt.gca()\n",
    "#ax0.invert_xaxis()\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Cost = 0','Cost = -0.005','Cost = -0.01'],fontsize=8)\n",
    "\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(coh_all*100,nobs_sa.T,'o-')\n",
    "ax0 = plt.gca()\n",
    "#ax0.invert_xaxis()\n",
    "plt.xlabel('Noise')\n",
    "plt.ylabel('Number of observations')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(cost,acc_sa,'o-')\n",
    "ax1 = plt.gca()\n",
    "ax1.invert_xaxis()\n",
    "plt.xlabel('Cost of observation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(cost)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(cost,nobs_sa,'o-')\n",
    "ax2 = plt.gca()\n",
    "ax2.invert_xaxis()\n",
    "\n",
    "plt.xlabel('Cost of observation')\n",
    "plt.ylabel('Number of time-steps')\n",
    "plt.xticks(cost)\n",
    "leg = plt.legend(aa,fontsize=8)\n",
    "leg.set_title('Noise')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 100\n",
    "tsteps = 20\n",
    "# get variables\n",
    "Y1 = monitor['action']\n",
    "h1 = monitor1['hidden-1']\n",
    "\n",
    "# calculate trial time steps\n",
    "A1 = np.zeros(Y1.shape)\n",
    "temp = 0\n",
    "for ii in xrange(len(Y1)):\n",
    "    temp = temp + 1\n",
    "    A1[ii] = temp\n",
    "    if Y1[ii] != (data_iter.n_output - 1) or temp == trial_length+1:\n",
    "        temp = 0\n",
    "\n",
    "\n",
    "# only focus on those trials at which a decision is being made\n",
    "idx = np.where((Y1 != data_iter.n_output - 1) & (A1==tsteps))[0]\n",
    "Y = Y1[idx]\n",
    "\n",
    "R = np.zeros((len(idx),tsteps,n_hidden))\n",
    "for ii in xrange(len(idx)):\n",
    "    R[ii] = h1[(idx[ii]-tsteps+1):(idx[ii]+1)]\n",
    "\n",
    "A = np.tile(np.expand_dims(val_iter.mean_image_count,2),reps = (1,1,784))\n",
    "B=1.0*val_iter.mean_image/A\n",
    "C=B[0,:,:]-B[1,:,:]\n",
    "D=np.mean(C**2,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Y\n",
    "CP = np.zeros((tsteps,n_hidden))\n",
    "for t in xrange(tsteps):\n",
    "    for N in xrange(n_hidden):\n",
    "        n = np.sum(C==0)\n",
    "        m = np.sum(C==1)\n",
    "        k = np.linspace(np.max(R[C==1,t,N]),np.min(R[C==1,t,N]),100)\n",
    "        ROC = np.zeros((2,100))\n",
    "        for ii in xrange(100):\n",
    "            \n",
    "            NTP = np.sum(R[C==0,t,N]>k[ii])\n",
    "            NFP = np.sum(R[C==1,t,N]>k[ii])\n",
    "            ROC[0,ii] = 1.0*NTP/n\n",
    "            ROC[1,ii] = 1.0*NFP/m\n",
    "        CP[t,N] = np.sum(np.diff(ROC[1,:])*ROC[0,:-1])\n",
    "        \n",
    "A=CP[:,np.mean(CP[3:,:],axis=0)>0.5]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.mean(A,axis=1))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('CP')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(CP)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('CP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.reshape((B[0,10,:]-B[1,10,:]),(28,28)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3))\n",
    "plt.clf()\n",
    "plt.subplot(121)\n",
    "plt.plot(np.mean(A,axis=1))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('CP')\n",
    "plt.ylim([0,1])\n",
    "\n",
    "\n",
    "sp2 = plt.subplot(122)\n",
    "plt.plot(D)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PK')\n",
    "sp2.axes.set_yticklabels([])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chainer1]",
   "language": "python",
   "name": "conda-env-chainer1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
